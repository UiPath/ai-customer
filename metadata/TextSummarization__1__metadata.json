{
  "changeLog": "",
  "cpu": 0,
  "description": "This is a abstractive text summarization model open sourced by Facebook AI Research. It is a sequence-to-sequence model based on the paper `BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension` by Lewis, et al.",
  "displayName": "TextSummarization",
  "gpu": 0,
  "inputDescription": "Text to be summarized as a String. Please note this model can be slow for long inputs.",
  "inputType": "JSON",
  "memory": 0,
  "mlPackageLanguage": "PYTHON36",
  "name": "TextSummarization",
  "outputDescription": "JSON with summarized text. The resulting output will have about 20-30% the length of the input",
  "processorType": "CPU",
  "projectId": "[project-id]",  
  "retrainable": false,
  "stagingUri": "[staging-uri]",
  "projectName": "Language Comprehension",
  "projectDescription": "Models performing cognitively challenging tasks such as text summarization and question answering",
  "tenantName": "Open-Source Packages",
  "minAIFabricVersion": "v20.7.1",
  "languageVersion": 0,
  "imagePath": "sfbrdevhelmweacr.azurecr.io/aicenter/textsummarization:1"
}